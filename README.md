# ğŸ—£ï¸ Gujarati Cross-Lingual Voice Assistant

> A dialect-aware voice AI that understands regional Gujarati dialects, processes speech intelligently using RAG + LLM, and responds in voice or text. The model learns from its own mistakes continuously.

---

## ğŸ” System Flow

```mermaid
flowchart TD
    A([ğŸ™ï¸ User speaks\nin any Gujarati dialect]) --> B

    subgraph ASR["ğŸ”Š ASR â€” Speech to Text"]
        B[Whisper / Wav2Vec2\nfine-tuned on 4 dialects]
    end

    B --> C

    subgraph NLU["ğŸ§  NLU â€” Language Understanding"]
        C[Dialect Identifier\nIndicBERT / MuRIL] --> D
        D[Intent + Entity\nExtraction]
    end

    D --> E

    subgraph RAG["ğŸ“š RAG â€” Retrieval Augmented Generation"]
        E[Query Vector Store\nFAISS / ChromaDB] --> F
        F[Retrieve relevant\ndialect context chunks] --> G
        G[Inject context\ninto LLM prompt]
    end

    G --> H

    subgraph LLM["ğŸ’¡ AI Brain â€” Response Generation"]
        H[IndicBERT / LLaMA\nfine-tuned on Gujarati] --> I
        I[Generate response\nin Standard Gujarati]
    end

    I --> J

    subgraph FEEDBACK["ğŸ”„ Self-Learning Loop"]
        J{User\nfeedback?}
        J -- Correction / Low confidence --> K[Log mistake\nto error store]
        K --> L[Auto-add to\nRAG vector store]
        L --> M[Re-embed &\nupdate knowledge base]
        M --> E
    end

    J -- Accepted --> N

    subgraph TTS["ğŸ”ˆ TTS â€” Text to Speech"]
        N[Coqui TTS /\nIndicTTS Gujarati voice]
    end

    N --> O([ğŸ“¢ User receives\nspeech or text response])

    style ASR fill:#1e3a5f,color:#fff
    style NLU fill:#2d5016,color:#fff
    style RAG fill:#5c2d00,color:#fff
    style LLM fill:#3d1a5f,color:#fff
    style FEEDBACK fill:#5f1a1a,color:#fff
    style TTS fill:#1a4a4a,color:#fff
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Tool | Purpose |
|---|---|---|
| **ASR** | `openai/whisper-small` | Speech â†’ text, fine-tuned on Gujarati dialects |
| **ASR alt** | `facebook/wav2vec2-base` | Alternate ASR backbone |
| **Dialect ID** | `google/muril-base-cased` | Classify which dialect (Surti/Kathiawari etc.) |
| **Embeddings** | `sentence-transformers` | Encode text for RAG vector store |
| **Vector DB** | `FAISS` / `ChromaDB` | Store & retrieve dialect knowledge chunks |
| **LLM** | `ai4bharat/IndicBERT` | Core language understanding & generation |
| **LLM alt** | `LLaMA 3 (fine-tuned)` | Larger model for generation tasks |
| **TTS** | `Coqui TTS` / `IndicTTS` | Text â†’ Gujarati speech |
| **Backend** | `FastAPI` (Python) | REST API for the pipeline |
| **Frontend** | `React` / `Next.js` | Web UI or mobile app |
| **Experiment tracking** | `MLflow` / `W&B` | Track model training runs |
| **Data** | `yt-dlp` + `youtube-comment-downloader` | Dialect data scraping |

---

## ğŸ“š RAG Implementation

The model does **not** just rely on its weights â€” it retrieves real dialect knowledge at inference time.

```
User query
    â†“
Embed query using sentence-transformers
    â†“
Search FAISS/ChromaDB for top-k similar dialect chunks
    â†“
Inject retrieved context â†’ LLM prompt
    â†“
LLM generates a context-grounded answer
```

**RAG knowledge base contains:**
- Dialect sentence examples (from our 2000 balanced rows)
- Dialect vocabulary mappings (Surti â†” Standard Gujarati)
- Common corrections from the self-learning store

---

## ğŸ”„ Self-Learning from Mistakes

When the model gets something wrong, it doesn't just fail â€” it learns:

```
Low confidence or user correction
    â†“
Error logged to mistake_store.json
    â†“
Re-embedded and added to RAG vector store
    â†“
Next identical/similar query uses corrected context
```

This means: **the more people use it, the smarter it gets**, without full retraining.

---

## ğŸ“Š Dialect Dataset (Phase 1 âœ…)

| Dialect | Region | Balanced Rows |
|---|---|---|
| Standard Gujarati | Ahmedabad / Gandhinagar | 500 âœ… |
| Surti | Surat / South Gujarat | 500 âœ… |
| Kathiawari | Rajkot / Saurashtra | 500 âœ… |
| Charotari | Anand / Kheda | 500 âœ… |

**Total: 2,000 rows â€” 500 per dialect â€” equal class weight for unbiased training**

---

## ğŸ—ºï¸ Project Phases

| Phase | Goal | Status |
|---|---|---|
| **Phase 1** | Data collection & balancing (2000 rows) | âœ… Done |
| **Phase 2** | Dialect classifier (IndicBERT / MuRIL) | ğŸ”œ Next |
| **Phase 3** | RAG pipeline setup (FAISS + embeddings) | ğŸ”œ Planned |
| **Phase 4** | ASR fine-tuning (Whisper on dialect audio) | ğŸ”œ Planned |
| **Phase 5** | LLM fine-tuning + TTS integration | ğŸ”œ Planned |
| **Phase 6** | Self-learning loop (mistake â†’ RAG update) | ğŸ”œ Planned |
| **Phase 7** | FastAPI backend + React frontend / App | ğŸ”œ Planned |

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ project_overview.md   â† detailed architecture doc
â”‚   â””â”€â”€ total_lang.csv        â† dialect reference
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  â† dialect CSVs (500 rows each)
â”‚   â”œâ”€â”€ processed/            â† tokenized / encoded data
â”‚   â””â”€â”€ combined/             â† train / val / test splits
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ scrape_top4.py        â† 4-dialect YouTube scraper
â”‚   â”œâ”€â”€ balance_data.py       â† balance to 500/dialect
â”‚   â”œâ”€â”€ topup_gaps.py         â† fill shortfalls
â”‚   â””â”€â”€ dialect_cleaner.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ asr/                  â† Whisper fine-tuning
â”‚   â”œâ”€â”€ nlu/                  â† dialect classifier + intent
â”‚   â”œâ”€â”€ tts/                  â† Coqui/IndicTTS wrapper
â”‚   â””â”€â”€ api/                  â† FastAPI backend
â”œâ”€â”€ models/                   â† saved checkpoints
â””â”€â”€ notebooks/                â† experiments & EDA
```

---

*Version 2.0 | Updated: 2026-02-19*
